{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 1: 손수 설계하는 선형회귀, 당뇨병 수치를 맞춰보자!\n",
    "\n",
    "## 개요\n",
    "- sklearn의 당뇨병 데이터셋을 사용한 선형회귀 모델 직접 구현\n",
    "- 목표: MSE 손실함수값 3000 이하 달성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이터 가져오기\n",
    "sklearn.datasets의 load_diabetes에서 데이터를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "df_X = data.data\n",
    "df_y = data.target\n",
    "\n",
    "print(\"특성 이름:\", data.feature_names)\n",
    "print(\"데이터 shape:\", df_X.shape)\n",
    "print(\"타겟 shape:\", df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델에 입력할 데이터 X 준비하기\n",
    "df_X를 numpy array로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(df_X)\n",
    "\n",
    "print(type(X), X.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델에 예측할 데이터 y 준비하기\n",
    "df_y를 numpy array로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_y)\n",
    "\n",
    "print(type(y), y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) train 데이터와 test 데이터로 분리하기\n",
    "데이터를 학습용 80%, 테스트용 20%로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 모델 준비하기\n",
    "### 가중치(W)와 편향(b) 초기화\n",
    "- W: 10개의 특성에 대한 가중치 벡터\n",
    "- b: 편향(bias) 스칼라값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # 재현성을 위한 시드 설정\n",
    "W = np.random.rand(X_train.shape[1])\n",
    "b = np.random.rand()\n",
    "\n",
    "print(\"가중치 개수:\", len(W))\n",
    "print(\"초기 W:\", W)\n",
    "print(\"초기 b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 함수 정의\n",
    "선형 회귀 모델: $y = X \\cdot W + b$\n",
    "\n",
    "각 특성에 대해 가중치를 곱하고 합산한 후 편향을 더합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    \"\"\"\n",
    "    선형 회귀 모델 함수\n",
    "    \n",
    "    Parameters:\n",
    "        X: 입력 데이터 (N x features)\n",
    "        W: 가중치 벡터 (features,)\n",
    "        b: 편향 스칼라\n",
    "    \n",
    "    Returns:\n",
    "        predictions: 예측값 (N,)\n",
    "    \"\"\"\n",
    "    predictions = 0\n",
    "    for i in range(len(W)):\n",
    "        predictions += X[:, i] * W[i]  # 모든 행에 대해 i번째 열(특징)을 가져와서 i번째 가중치를 곱함\n",
    "    predictions += b  # 가중치 합산 후 편향을 더함\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 손실함수 loss 정의하기\n",
    "### MSE (Mean Squared Error) 함수\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}(y_{pred} - y_{true})^2$$\n",
    "\n",
    "예측값과 실제값 차이의 제곱 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(a, b):\n",
    "    \"\"\"\n",
    "    평균 제곱 오차 (Mean Squared Error)\n",
    "    \"\"\"\n",
    "    mse = ((a - b) ** 2).mean()\n",
    "    return mse\n",
    "\n",
    "def loss(X, W, b, y):\n",
    "    \"\"\"\n",
    "    손실 함수 - MSE를 사용하여 예측값과 실제값의 차이를 계산\n",
    "    \"\"\"\n",
    "    predictions = model(X, W, b)  # 모델이 예측한 결과값\n",
    "    L = MSE(predictions, y)       # 평균제곱 오차: 예측값과 실제값 사이의 오차\n",
    "    return L\n",
    "\n",
    "print(\"초기 손실값:\", loss(X_train, W, b, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 기울기를 구하는 gradient 함수 구현하기\n",
    "### 경사하강법 (Gradient Descent)\n",
    "MSE 손실함수의 미분:\n",
    "$$\\frac{\\partial L}{\\partial W} = \\frac{2}{N} X^T (y_{pred} - y)$$\n",
    "$$\\frac{\\partial L}{\\partial b} = \\frac{2}{N} \\sum(y_{pred} - y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    \"\"\"\n",
    "    경사하강법을 위한 기울기 계산 함수\n",
    "    \n",
    "    Parameters:\n",
    "        X: 입력 데이터\n",
    "        W: 가중치\n",
    "        b: 편향\n",
    "        y: 실제값\n",
    "    \n",
    "    Returns:\n",
    "        dW: W에 대한 기울기\n",
    "        db: b에 대한 기울기\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    y_pred = model(X, W, b)\n",
    "    \n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)  # W에 대한 편미분\n",
    "    db = 2 * (y_pred - y).mean()         # b에 대한 편미분\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) 하이퍼 파라미터인 학습률 설정하기\n",
    "학습률(Learning Rate)은 경사하강법에서 한 번에 이동하는 크기를 결정합니다.\n",
    "- 너무 크면: 발산할 수 있음\n",
    "- 너무 작으면: 학습이 느려짐\n",
    "\n",
    "당뇨병 데이터는 이미 정규화되어 있어 비교적 높은 학습률 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (9) 모델 학습하기\n",
    "경사하강법으로 가중치와 편향을 업데이트합니다.\n",
    "$$W = W - \\alpha \\cdot \\frac{\\partial L}{\\partial W}$$\n",
    "$$b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "EPOCHS = 2000\n",
    "\n",
    "for i in range(1, EPOCHS + 1):\n",
    "    dW, db = gradient(X_train, W, b, y_train)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X_train, W, b, y_train)\n",
    "    losses.append(L)\n",
    "    if i % 200 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10) test 데이터에 대한 성능 확인하기\n",
    "학습된 모델을 테스트 데이터에 적용하여 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(X_test, W, b)\n",
    "mse = loss(X_test, W, b, y_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"목표 MSE (3000 이하):\", \"달성!\" if mse < 3000 else \"미달성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 성능 지표: R² Score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, prediction)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (11) 정답 데이터와 예측한 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_test[:, 0], y_test, label='Actual')\n",
    "plt.scatter(X_test[:, 0], prediction, label='Predicted')\n",
    "plt.xlabel('Feature 1 (age)')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 시각화: 실제값 vs 예측값 비교\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 그래프 1: 실제값 vs 예측값\n",
    "axes[0].scatter(y_test, prediction, alpha=0.7)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect')\n",
    "axes[0].set_xlabel('Actual')\n",
    "axes[0].set_ylabel('Predicted')\n",
    "axes[0].set_title('Actual vs Predicted')\n",
    "axes[0].legend()\n",
    "\n",
    "# 그래프 2: 손실값 변화\n",
    "axes[1].plot(losses)\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Loss (MSE)')\n",
    "axes[1].set_title('Training Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"최종 결과 요약\")\n",
    "print(\"=\"*50)\n",
    "print(f\"학습된 가중치 W: {W}\")\n",
    "print(f\"학습된 편향 b: {b:.4f}\")\n",
    "print(f\"Train MSE: {losses[-1]:.4f}\")\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print()\n",
    "print(\"체크사항:\")\n",
    "print(f\"1) 회귀모델 예측정확도 (R²): {r2:.4f}\")\n",
    "print(f\"2) MSE 손실함수값 3000 이하: {mse:.4f}\", \"-> 달성!\" if mse < 3000 else \"-> 미달성\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
