{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# [MAIN QUEST 01] Space Titanic - ë°ì´í„° EDA ë° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§\n",
    "\n",
    "**ì‘ì„±ì:** ê¹€ì°½ì¼\n",
    "**ì‘ì„±ì¼:** 2026.01.26\n",
    "**ê³¼ì œ:**  Main Quest 01\n",
    "**ëª©í‘œ:** Space Titanic ë°ì´í„° ë¶„ì„ ë° Transported ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ (ì •í™•ë„ 80.5% ì´ìƒ)\n",
    "\n",
    "---\n",
    "\n",
    "##  ëª©ì°¨ (Table of Contents)\n",
    "\n",
    "1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)\n",
    "2. [ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸](#2-ë°ì´í„°-ë¡œë“œ-ë°-ê¸°ë³¸-ì •ë³´-í™•ì¸)\n",
    "3. [íƒ€ê²Ÿ ë³€ìˆ˜ ë° ê²°ì¸¡ì¹˜ ë¶„ì„](#3-íƒ€ê²Ÿ-ë³€ìˆ˜-ë°-ê²°ì¸¡ì¹˜-ë¶„ì„)\n",
    "4. [íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)](#4-íƒìƒ‰ì -ë°ì´í„°-ë¶„ì„-eda)\n",
    "   - 4.1 ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬\n",
    "   - 4.2 Cabin êµ¬ì¡° ë¶„ì„\n",
    "   - 4.3 ë³€ìˆ˜ë³„ Transported ê´€ê³„\n",
    "   - 4.4 ì†Œë¹„ íŒ¨í„´ ë¶„ì„\n",
    "   - 4.5 ê·¸ë£¹ ë¶„ì„\n",
    "   - 4.6 Name ë¶„ì„\n",
    "5. [ë°ì´í„° ì „ì²˜ë¦¬](#5-ë°ì´í„°-ì „ì²˜ë¦¬)\n",
    "   - 5.1 ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "   - 5.2 íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "   - 5.3 ì¸ì½”ë”©\n",
    "6. [ëª¨ë¸ë§](#6-ëª¨ë¸ë§)\n",
    "   - 6.1 Baseline ëª¨ë¸\n",
    "   - 6.2 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "   - 6.3 ìµœì¢… ëª¨ë¸ ì„ íƒ\n",
    "7. [Test ì˜ˆì¸¡ ë° ì œì¶œ](#7-test-ì˜ˆì¸¡-ë°-ì œì¶œ)\n",
    "8. [ê²°ê³¼ ìš”ì•½ (Summary)](#8-ê²°ê³¼-ìš”ì•½-summary)\n",
    "9. [íšŒê³  (Reflection)](#9-íšŒê³ -reflection)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "### 1.1 ë°°ê²½\n",
    "Space Titanicì€ Kaggleì˜ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡ ë¬¸ì œë¥¼ ë³€í˜•í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ, ìš°ì£¼ì„  ìŠ¹ê°ë“¤ì´ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì´ë™(Transported)í–ˆëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì…ë‹ˆë‹¤.\n",
    "\n",
    "### 1.2 ëª©í‘œ\n",
    "- Space Titanic ë°ì´í„°ë¥¼ íƒìƒ‰ì ìœ¼ë¡œ ë¶„ì„(EDA)\n",
    "- ìŠ¹ê°ì˜ Transported ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ\n",
    "- **ì •í™•ë„ 80.5% ì´ìƒ ë‹¬ì„±**\n",
    "\n",
    "### 1.3 ë°ì´í„°ì…‹ êµ¬ì¡°\n",
    "- **Train ë°ì´í„°:** 8,693ëª…ì˜ ìŠ¹ê° (14ê°œ ë³€ìˆ˜)\n",
    "- **Test ë°ì´í„°:** 4,277ëª…ì˜ ìŠ¹ê° (13ê°œ ë³€ìˆ˜, Transported ì œì™¸)\n",
    "- **ì£¼ìš” ë³€ìˆ˜:**\n",
    "  - PassengerId: ìŠ¹ê° ê³ ìœ  ID\n",
    "  - HomePlanet: ì¶œë°œ í–‰ì„±\n",
    "  - CryoSleep: ëƒ‰ë™ìˆ˜ë©´ ì—¬ë¶€\n",
    "  - Cabin: ê°ì‹¤ ë²ˆí˜¸\n",
    "  - Destination: ëª©ì ì§€\n",
    "  - Age: ë‚˜ì´\n",
    "  - VIP: VIP ì—¬ë¶€\n",
    "  - RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: ì†Œë¹„ ê¸ˆì•¡\n",
    "  - Name: ì´ë¦„\n",
    "  - **Transported (íƒ€ê²Ÿ):** ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì´ë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
    "\n",
    "---\n"
   ],
   "id": "2c3f2a0107632727"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T07:25:00.489155Z",
     "start_time": "2026-01-26T07:24:59.766780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# ì™„ì„±ëœ í”„ë¡œì íŠ¸ë¥¼ Jupyter Notebook íŒŒì¼ë¡œ ìƒì„±\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Jupyter Notebook íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import nbformat as nbf\n",
    "\n",
    "# ìƒˆ ë…¸íŠ¸ë¶ ìƒì„±\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# ì…€ ë¦¬ìŠ¤íŠ¸\n",
    "cells = []\n",
    "\n",
    "# ========== ì œëª© ë° ê°œìš” (Markdown) ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"# [MAIN QUEST 01] Space Titanic - ë°ì´í„° EDA ë° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§\n",
    "\n",
    "**ì‘ì„±ì:** Changil\n",
    "**ì‘ì„±ì¼:** 2026.01.26\n",
    "**ê³¼ì œ:** ì•„ì´í  ì—”ì§€ë‹ˆì–´ ì–‘ì„±ê³¼ì • Main Quest 01\n",
    "**ëª©í‘œ:** Space Titanic ë°ì´í„° ë¶„ì„ ë° Transported ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ (ì •í™•ë„ 80.5% ì´ìƒ)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ëª©ì°¨ (Table of Contents)\n",
    "\n",
    "1. í”„ë¡œì íŠ¸ ê°œìš”\n",
    "2. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
    "3. íƒ€ê²Ÿ ë³€ìˆ˜ ë° ê²°ì¸¡ì¹˜ ë¶„ì„\n",
    "4. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)\n",
    "5. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "6. ëª¨ë¸ë§\n",
    "7. Test ì˜ˆì¸¡ ë° ì œì¶œ\n",
    "8. ê²°ê³¼ ìš”ì•½\n",
    "9. íšŒê³ \n",
    "10. ì°¸ê³  ë¬¸í—Œ\n",
    "\n",
    "---\n",
    "\n",
    "## 1. í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "### ë°°ê²½\n",
    "Space Titanicì€ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡ ë¬¸ì œë¥¼ ë³€í˜•í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ, ìš°ì£¼ì„  ìŠ¹ê°ë“¤ì´ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì´ë™(Transported)í–ˆëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì…ë‹ˆë‹¤.\n",
    "\n",
    "### ëª©í‘œ\n",
    "- Space Titanic ë°ì´í„° íƒìƒ‰ì  ë¶„ì„(EDA)\n",
    "- Transported ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ\n",
    "- **ì •í™•ë„ 80.5% ì´ìƒ ë‹¬ì„±**\n",
    "\n",
    "### ë°ì´í„°ì…‹\n",
    "- Train: 8,693ëª… (14ê°œ ë³€ìˆ˜)\n",
    "- Test: 4,277ëª… (13ê°œ ë³€ìˆ˜)\n",
    "\"\"\"))\n",
    "\n",
    "# ========== 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## 2. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸\\n\\n### 2.1 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import missingno as msno\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì •\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\"\"\"))\n",
    "\n",
    "# ========== 2. ë°ì´í„° ë¡œë“œ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"### 2.2 ë°ì´í„° ë¡œë“œ\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(f\"Train ë°ì´í„° í¬ê¸°: {train_df.shape}\")\n",
    "print(f\"Test ë°ì´í„° í¬ê¸°: {test_df.shape}\")\n",
    "print(f\"\\\\nì»¬ëŸ¼ ëª©ë¡:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "# ê¸°ë³¸ ì •ë³´\n",
    "print(\"\\\\në°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\\\nì²˜ìŒ 5ê°œ í–‰:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\\\nê¸°ìˆ  í†µê³„:\")\n",
    "display(train_df.describe())\"\"\"))\n",
    "\n",
    "# ========== 3. íƒ€ê²Ÿ ë³€ìˆ˜ ë° ê²°ì¸¡ì¹˜ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 3. íƒ€ê²Ÿ ë³€ìˆ˜ ë° ê²°ì¸¡ì¹˜ ë¶„ì„\n",
    "\n",
    "### ë…¼ë¦¬ì  ê·¼ê±°\n",
    "íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ë¶„í¬ì™€ ê²°ì¸¡ì¹˜ íŒ¨í„´ì„ ë¨¼ì € íŒŒì•…í•˜ì—¬:\n",
    "- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì—¬ë¶€ í™•ì¸\n",
    "- ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½\n",
    "- ë°ì´í„° í’ˆì§ˆ ì ê²€\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬\n",
    "print(\"=\" * 60)\n",
    "print(\"íƒ€ê²Ÿ ë³€ìˆ˜ (Transported) ë¶„í¬\")\n",
    "print(\"=\" * 60)\n",
    "print(train_df['Transported'].value_counts())\n",
    "print(f\"\\\\në¹„ìœ¨:\\\\n{train_df['Transported'].value_counts(normalize=True)}\")\n",
    "\n",
    "# íŒŒì´ ì°¨íŠ¸\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].pie(train_df['Transported'].value_counts(),\n",
    "            labels=['Not Transported', 'Transported'],\n",
    "            autopct='%1.1f%%',\n",
    "            explode=[0.05, 0.05],\n",
    "            shadow=True)\n",
    "axes[0].set_title('íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬', fontweight='bold')\n",
    "\n",
    "sns.countplot(data=train_df, x='Transported', ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('Transported ê°œìˆ˜', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(\"\\\\n\" + \"=\" * 60)\n",
    "print(\"ê²°ì¸¡ì¹˜ í˜„í™©\")\n",
    "print(\"=\" * 60)\n",
    "missing = train_df.isnull().sum()\n",
    "missing_pct = (train_df.isnull().sum() / len(train_df)) * 100\n",
    "missing_df = pd.DataFrame({'ê²°ì¸¡ì¹˜ ê°œìˆ˜': missing, 'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': missing_pct})\n",
    "print(missing_df[missing_df['ê²°ì¸¡ì¹˜ ê°œìˆ˜'] > 0].sort_values('ê²°ì¸¡ì¹˜ ê°œìˆ˜', ascending=False))\n",
    "\n",
    "# missingno ì‹œê°í™”\n",
    "msno.matrix(train_df, sort='descending', figsize=(12, 6))\n",
    "plt.title('ê²°ì¸¡ì¹˜ íŒ¨í„´ (í°ìƒ‰ = ê²°ì¸¡)', fontweight='bold')\n",
    "plt.show()\"\"\"))\n",
    "\n",
    "# ========== 4. EDA ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 4. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)\n",
    "\n",
    "### 4.1 ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ë° Cabin ë¶„ì„\n",
    "\n",
    "**ë…¼ë¦¬ì  ê·¼ê±°:**\n",
    "- ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬ ë°ì´í„° ì´í•´\n",
    "- Cabinì—ì„œ Deck, Side ì •ë³´ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€ í”¼ì²˜ ìƒì„±\n",
    "- ê° ë³€ìˆ˜ê°€ Transportedì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬\n",
    "categorical_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\\\n[{col}]\")\n",
    "    print(train_df[col].value_counts())\n",
    "    print(f\"ê²°ì¸¡ì¹˜: {train_df[col].isnull().sum()}ê°œ\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "# Cabin ë¶„ë¦¬\n",
    "print(\"\\\\nCabin ë¶„ë¦¬ ì‘ì—…...\")\n",
    "train_df['Deck'] = train_df['Cabin'].str.split('/').str[0]\n",
    "train_df['Cabin_num'] = train_df['Cabin'].str.split('/').str[1]\n",
    "train_df['Side'] = train_df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "test_df['Deck'] = test_df['Cabin'].str.split('/').str[0]\n",
    "test_df['Cabin_num'] = test_df['Cabin'].str.split('/').str[1]\n",
    "test_df['Side'] = test_df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "print(\"âœ… Cabin â†’ Deck, Cabin_num, Side ë¶„ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬', fontsize=16, fontweight='bold')\n",
    "\n",
    "viz_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "\n",
    "for idx, col in enumerate(viz_cols):\n",
    "    row = idx // 3\n",
    "    col_idx = idx % 3\n",
    "    ax = axes[row, col_idx]\n",
    "\n",
    "    data_counts = train_df[col].value_counts()\n",
    "    data_counts.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n",
    "    ax.set_title(f'{col} ë¶„í¬', fontweight='bold')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\"))\n",
    "\n",
    "# ========== ë³€ìˆ˜ì™€ Transported ê´€ê³„ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 4.2 ë³€ìˆ˜ì™€ Transported ê´€ê³„ ë¶„ì„\n",
    "\n",
    "**ì¸ì‚¬ì´íŠ¸ ë„ì¶œ:**\n",
    "ì´ ë¶„ì„ì„ í†µí•´ ì–´ë–¤ ë³€ìˆ˜ê°€ Transportedì— ê°•í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ë²”ì£¼í˜• ë³€ìˆ˜ì™€ Transported ê´€ê³„\n",
    "categorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('ë²”ì£¼í˜• ë³€ìˆ˜ë³„ Transported ë¹„ìœ¨', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    row = idx // 3\n",
    "    col_idx = idx % 3\n",
    "    ax = axes[row, col_idx]\n",
    "\n",
    "    transported_rate = train_df.groupby(col)['Transported'].mean().sort_values()\n",
    "    transported_rate.plot(kind='barh', ax=ax, color='coral')\n",
    "    ax.set_xlabel('Transported ë¹„ìœ¨')\n",
    "    ax.set_title(f'{col}')\n",
    "    ax.axvline(x=0.5, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    for i, v in enumerate(transported_rate.values):\n",
    "        ax.text(v, i, f' {v:.2%}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Age vs Transported\n",
    "print(\"\\\\nAge vs Transported ë¶„ì„\")\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.histplot(data=train_df, x='Age', hue='Transported', binwidth=1, kde=True, bins=80)\n",
    "plt.title('Age Distribution by Transported', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nğŸ’¡ ë°œê²¬í•œ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(\"- CryoSleep=Trueì¸ ìŠ¹ê°ì˜ ì´ë™ë¥ ì´ ë†’ìŒ\")\n",
    "print(\"- 0~18ì„¸ ìŠ¹ê°ì˜ ì´ë™ë¥ ì´ ë†’ìŒ\")\n",
    "print(\"- HomePlanet, Destinationì— ë”°ë¥¸ ì´ë™ë¥  ì°¨ì´ ì¡´ì¬\")\"\"\"))\n",
    "\n",
    "# ========== ì†Œë¹„ íŒ¨í„´ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 4.3 ì†Œë¹„ íŒ¨í„´ ë¶„ì„\n",
    "\n",
    "**ë…¼ë¦¬ì  ê·¼ê±°:**\n",
    "ì†Œë¹„ ê´€ë ¨ ë³€ìˆ˜(RoomService, FoodCourt ë“±)ë¥¼ í•©ì‚°í•˜ì—¬ TotalSpending íŒŒìƒ ë³€ìˆ˜ ìƒì„±\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ì†Œë¹„ ë³€ìˆ˜\n",
    "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# TotalSpending ìƒì„±\n",
    "train_df['TotalSpending'] = train_df[spending_cols].fillna(0).sum(axis=1)\n",
    "test_df['TotalSpending'] = test_df[spending_cols].fillna(0).sum(axis=1)\n",
    "\n",
    "train_df['HasSpending'] = (train_df['TotalSpending'] > 0).astype(int)\n",
    "test_df['HasSpending'] = (test_df['TotalSpending'] > 0).astype(int)\n",
    "\n",
    "print(\"âœ… TotalSpending, HasSpending ë³€ìˆ˜ ìƒì„±\")\n",
    "print(f\"\\\\nì†Œë¹„ ì—¬ë¶€ ë¶„í¬:\")\n",
    "print(train_df['HasSpending'].value_counts())\n",
    "\n",
    "# ì†Œë¹„ ì—¬ë¶€ë³„ Transported ë¹„ìœ¨\n",
    "print(\"\\\\nì†Œë¹„ ì—¬ë¶€ë³„ Transported ë¹„ìœ¨:\")\n",
    "print(pd.crosstab(train_df['HasSpending'], train_df['Transported'], normalize='index'))\"\"\"))\n",
    "\n",
    "# ========== ê·¸ë£¹ ë¶„ì„ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 4.4 ê·¸ë£¹ ë¶„ì„\n",
    "\n",
    "**ë…¼ë¦¬ì  ê·¼ê±°:**\n",
    "PassengerIdì—ì„œ ê·¸ë£¹ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê°€ì¡±/ì¼í–‰ ë‹¨ìœ„ íŒ¨í„´ íŒŒì•…\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# PassengerIdì—ì„œ ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ\n",
    "train_df['Group'] = train_df['PassengerId'].str.split('_').str[0]\n",
    "train_df['GroupMember'] = train_df['PassengerId'].str.split('_').str[1]\n",
    "\n",
    "test_df['Group'] = test_df['PassengerId'].str.split('_').str[0]\n",
    "test_df['GroupMember'] = test_df['PassengerId'].str.split('_').str[1]\n",
    "\n",
    "# ê·¸ë£¹ í¬ê¸° ê³„ì‚°\n",
    "group_size_train = train_df.groupby('Group').size().reset_index(name='GroupSize')\n",
    "group_size_test = test_df.groupby('Group').size().reset_index(name='GroupSize')\n",
    "\n",
    "train_df = train_df.merge(group_size_train, on='Group', how='left')\n",
    "test_df = test_df.merge(group_size_test, on='Group', how='left')\n",
    "\n",
    "train_df['IsAlone'] = (train_df['GroupSize'] == 1).astype(int)\n",
    "test_df['IsAlone'] = (test_df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "print(\"âœ… Group, GroupSize, IsAlone ë³€ìˆ˜ ìƒì„±\")\n",
    "print(f\"\\\\ní˜¼ì ì—¬í–‰: {(train_df['IsAlone']==1).sum()}ëª…\")\n",
    "print(f\"ì¼í–‰ ìˆìŒ: {(train_df['IsAlone']==0).sum()}ëª…\")\n",
    "\n",
    "print(\"\\\\ní˜¼ì vs ì¼í–‰ Transported ë¹„ìœ¨:\")\n",
    "print(train_df.groupby('IsAlone')['Transported'].mean())\"\"\"))\n",
    "\n",
    "# ========== Name ë¶„ì„ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 4.5 Name ë¶„ì„ ë° ì¶”ê°€ íŒŒìƒ ë³€ìˆ˜\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# LastName ì¶”ì¶œ\n",
    "train_df['LastName'] = train_df['Name'].str.split().str[-1]\n",
    "test_df['LastName'] = test_df['Name'].str.split().str[-1]\n",
    "\n",
    "# FamilySize ê³„ì‚°\n",
    "train_df['FamilySize'] = train_df.groupby(['Group', 'LastName'])['PassengerId'].transform('count')\n",
    "test_df['FamilySize'] = test_df.groupby(['Group', 'LastName'])['PassengerId'].transform('count')\n",
    "\n",
    "# AgeGroup ìƒì„±\n",
    "def age_group(age):\n",
    "    if pd.isna(age):\n",
    "        return 'Unknown'\n",
    "    elif age < 13:\n",
    "        return 'Child'\n",
    "    elif age < 18:\n",
    "        return 'Teen'\n",
    "    elif age < 25:\n",
    "        return 'Young Adult'\n",
    "    elif age < 40:\n",
    "        return 'Adult'\n",
    "    elif age < 60:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "train_df['AgeGroup'] = train_df['Age'].apply(age_group)\n",
    "test_df['AgeGroup'] = test_df['Age'].apply(age_group)\n",
    "\n",
    "# SpendingCategory ìƒì„±\n",
    "def spending_category(spending):\n",
    "    if spending == 0:\n",
    "        return 'No Spending'\n",
    "    elif spending < 100:\n",
    "        return 'Low'\n",
    "    elif spending < 500:\n",
    "        return 'Medium'\n",
    "    elif spending < 2000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "\n",
    "train_df['SpendingCategory'] = train_df['TotalSpending'].apply(spending_category)\n",
    "test_df['SpendingCategory'] = test_df['TotalSpending'].apply(spending_category)\n",
    "\n",
    "print(\"âœ… LastName, FamilySize, AgeGroup, SpendingCategory ë³€ìˆ˜ ìƒì„±\")\n",
    "\n",
    "# ìƒì„±ëœ íŒŒìƒ ë³€ìˆ˜ ëª©ë¡\n",
    "new_features = ['Deck', 'Side', 'TotalSpending', 'HasSpending',\n",
    "                'Group', 'GroupSize', 'IsAlone', 'LastName', 'FamilySize',\n",
    "                'AgeGroup', 'SpendingCategory']\n",
    "print(f\"\\\\nì´ {len(new_features)}ê°œì˜ íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ\")\"\"\"))\n",
    "\n",
    "# ========== 5. ì „ì²˜ë¦¬ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 5. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "### 5.1 ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "\n",
    "**ë…¼ë¦¬ì  ê·¼ê±°:**\n",
    "- CryoSleep=True â†’ ì†Œë¹„ëŠ” 0 (ë…¼ë¦¬ì  ì¼ê´€ì„±)\n",
    "- ë²”ì£¼í˜• ë³€ìˆ˜ â†’ ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ì›€\n",
    "- Age â†’ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "- ì†Œë¹„ ë³€ìˆ˜ â†’ 0ìœ¼ë¡œ ì±„ì›€ (ì†Œë¹„í•˜ì§€ ì•ŠìŒìœ¼ë¡œ ê°„ì£¼)\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ í™•ì¸\n",
    "print(\"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „:\")\n",
    "print(train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
    "\n",
    "# 1) CryoSleep=Trueì´ë©´ ì†Œë¹„ëŠ” 0\n",
    "for df in [train_df, test_df]:\n",
    "    cryosleep_mask = (df['CryoSleep'] == 'True')\n",
    "    for col in spending_cols:\n",
    "        df.loc[cryosleep_mask, col] = df.loc[cryosleep_mask, col].fillna(0)\n",
    "\n",
    "# 2) ë²”ì£¼í˜• ë³€ìˆ˜ â†’ ìµœë¹ˆê°’\n",
    "for col in ['HomePlanet', 'Destination', 'CryoSleep', 'VIP', 'Deck', 'Side']:\n",
    "    mode_value = train_df[col].mode()[0]\n",
    "    train_df[col].fillna(mode_value, inplace=True)\n",
    "    test_df[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# 3) Age â†’ ì¤‘ì•™ê°’\n",
    "age_median = train_df['Age'].median()\n",
    "train_df['Age'].fillna(age_median, inplace=True)\n",
    "test_df['Age'].fillna(age_median, inplace=True)\n",
    "\n",
    "# AgeGroup ì¬ìƒì„±\n",
    "train_df['AgeGroup'] = train_df['Age'].apply(age_group)\n",
    "test_df['AgeGroup'] = test_df['Age'].apply(age_group)\n",
    "\n",
    "# 4) ì†Œë¹„ ë³€ìˆ˜ â†’ 0\n",
    "for col in spending_cols:\n",
    "    train_df[col].fillna(0, inplace=True)\n",
    "    test_df[col].fillna(0, inplace=True)\n",
    "\n",
    "# TotalSpending ì¬ê³„ì‚°\n",
    "train_df['TotalSpending'] = train_df[spending_cols].sum(axis=1)\n",
    "test_df['TotalSpending'] = test_df[spending_cols].sum(axis=1)\n",
    "\n",
    "train_df['HasSpending'] = (train_df['TotalSpending'] > 0).astype(int)\n",
    "test_df['HasSpending'] = (test_df['TotalSpending'] > 0).astype(int)\n",
    "\n",
    "train_df['SpendingCategory'] = train_df['TotalSpending'].apply(spending_category)\n",
    "test_df['SpendingCategory'] = test_df['TotalSpending'].apply(spending_category)\n",
    "\n",
    "# 5) Cabin_num â†’ ì¤‘ì•™ê°’\n",
    "train_df['Cabin_num'].fillna(train_df['Cabin_num'].median(), inplace=True)\n",
    "test_df['Cabin_num'].fillna(test_df['Cabin_num'].median(), inplace=True)\n",
    "\n",
    "# 6) Name â†’ Unknown\n",
    "train_df['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "test_df['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "train_df['LastName'].fillna('Unknown', inplace=True)\n",
    "test_df['LastName'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"\\\\nê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„:\")\n",
    "print(train_df.isnull().sum().sum(), \"ê°œ\")\n",
    "print(\"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\"\"\"))\n",
    "\n",
    "# ========== ì¸ì½”ë”© ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 5.2 ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "\n",
    "**ë…¼ë¦¬ì  ê·¼ê±°:**\n",
    "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë¯€ë¡œ One-Hot Encoding ìˆ˜í–‰\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# Boolean ë³€ìˆ˜ â†’ 1/0\n",
    "train_df['Transported'] = train_df['Transported'].astype(int)\n",
    "train_df['CryoSleep'] = (train_df['CryoSleep'] == 'True').astype(int)\n",
    "test_df['CryoSleep'] = (test_df['CryoSleep'] == 'True').astype(int)\n",
    "train_df['VIP'] = (train_df['VIP'] == 'True').astype(int)\n",
    "test_df['VIP'] = (test_df['VIP'] == 'True').astype(int)\n",
    "\n",
    "# One-Hot Encoding\n",
    "categorical_features = ['HomePlanet', 'Destination', 'Deck', 'Side', 'AgeGroup', 'SpendingCategory']\n",
    "\n",
    "train_df_encoded = pd.get_dummies(train_df, columns=categorical_features, drop_first=True)\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Train-Test ì»¬ëŸ¼ ì •ë ¬\n",
    "train_cols = set(train_df_encoded.columns) - {'Transported'}\n",
    "test_cols = set(test_df_encoded.columns)\n",
    "\n",
    "for col in train_cols - test_cols:\n",
    "    test_df_encoded[col] = 0\n",
    "\n",
    "for col in test_cols - train_cols:\n",
    "    test_df_encoded.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°\n",
    "drop_columns = ['PassengerId', 'Name', 'Cabin', 'LastName', 'Group', 'GroupMember', 'Cabin_num']\n",
    "train_df_encoded.drop([col for col in drop_columns if col in train_df_encoded.columns], axis=1, inplace=True)\n",
    "test_df_encoded.drop([col for col in drop_columns if col in test_df_encoded.columns], axis=1, inplace=True)\n",
    "\n",
    "print(f\"âœ… ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "print(f\"Train shape: {train_df_encoded.shape}\")\n",
    "print(f\"Test shape: {test_df_encoded.shape}\")\n",
    "\n",
    "# X, y ë¶„ë¦¬\n",
    "X_train_full = train_df_encoded.drop('Transported', axis=1)\n",
    "y_train_full = train_df_encoded['Transported']\n",
    "X_test = test_df_encoded.copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"\\\\nX_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\"\"\"))\n",
    "\n",
    "# ========== 6. ëª¨ë¸ë§ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 6. ëª¨ë¸ë§\n",
    "\n",
    "### 6.1 Baseline ëª¨ë¸ (Random Forest, XGBoost)\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Validation ì •í™•ë„: {val_acc_rf:.4f} ({val_acc_rf*100:.2f}%)\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "                          random_state=RANDOM_STATE, n_jobs=-1, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_xgb = xgb_model.predict(X_val)\n",
    "val_acc_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Validation ì •í™•ë„: {val_acc_xgb:.4f} ({val_acc_xgb*100:.2f}%)\")\"\"\"))\n",
    "\n",
    "# ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 6.2 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "**ëª©í‘œ:** GridSearchCVë¥¼ í†µí•´ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# XGBoost íŠœë‹ (ì‹œê°„ ê´€ê³„ìƒ ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ)\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBClassifier(random_state=RANDOM_STATE, n_jobs=-1, eval_metric='logloss'),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ GridSearchCV ì§„í–‰ ì¤‘...\")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\\\nâœ… ìµœì  íŒŒë¼ë¯¸í„°: {xgb_grid.best_params_}\")\n",
    "print(f\"âœ… ìµœê³  CV ì ìˆ˜: {xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_val_pred_xgb_best = xgb_best.predict(X_val)\n",
    "val_acc_xgb_best = accuracy_score(y_val, y_val_pred_xgb_best)\n",
    "\n",
    "print(f\"âœ… Validation ì •í™•ë„: {val_acc_xgb_best:.4f} ({val_acc_xgb_best*100:.2f}%)\")\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ ì„ íƒ\n",
    "final_model = xgb_best\n",
    "final_val_acc = val_acc_xgb_best\n",
    "\n",
    "if final_val_acc >= 0.805:\n",
    "    print(f\"\\\\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ({final_val_acc*100:.2f}% >= 80.5%)\")\n",
    "else:\n",
    "    print(f\"\\\\nâš ï¸ ëª©í‘œ ë¯¸ë‹¬ì„± ({final_val_acc*100:.2f}% < 80.5%)\")\"\"\"))\n",
    "\n",
    "# ========== Feature Importance ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"### 6.3 íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„\n",
    "\n",
    "**ì¸ì‚¬ì´íŠ¸:** ì–´ë–¤ ë³€ìˆ˜ê°€ ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ”ì§€ íŒŒì•…\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': final_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 ì¤‘ìš” íŠ¹ì„±:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['Importance'], color='teal')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importance', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\"))\n",
    "\n",
    "# ========== 7. Test ì˜ˆì¸¡ ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 7. Test ì˜ˆì¸¡ ë° ì œì¶œ\n",
    "\n",
    "ì „ì²´ Train ë°ì´í„°ë¡œ ì¬í•™ìŠµ í›„ Test ë°ì´í„° ì˜ˆì¸¡\"\"\"))\n",
    "\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"# ì „ì²´ Train ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Test ì˜ˆì¸¡\n",
    "X_test_aligned = X_test[X_train_full.columns]\n",
    "test_predictions = final_model.predict(X_test_aligned)\n",
    "\n",
    "print(f\"ì˜ˆì¸¡ ì™„ë£Œ: {len(test_predictions)}ëª…\")\n",
    "print(f\"Transported=True: {(test_predictions == 1).sum()}ëª…\")\n",
    "print(f\"Transported=False: {(test_predictions == 0).sum()}ëª…\")\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "original_test = pd.read_csv('test.csv')\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': original_test['PassengerId'],\n",
    "    'Transported': test_predictions.astype(bool)\n",
    "})\n",
    "\n",
    "submission.to_csv('spaceship_titanic_submission.csv', index=False)\n",
    "print(\"\\\\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: spaceship_titanic_submission.csv\")\"\"\"))\n",
    "\n",
    "# ========== 8. Summary ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 8. ê²°ê³¼ ìš”ì•½ (Summary)\n",
    "\n",
    "### ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬:** ë…¼ë¦¬ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²˜ë¦¬ (CryoSleepâ†’ì†Œë¹„ 0, ìµœë¹ˆê°’, ì¤‘ì•™ê°’)\n",
    "- **íŒŒìƒ ë³€ìˆ˜:** 15ê°œ ìƒì„± (Deck, TotalSpending, GroupSize, IsAlone, FamilySize, AgeGroup ë“±)\n",
    "- **ì¸ì½”ë”©:** One-Hot Encoding ì ìš©\n",
    "\n",
    "### EDA ì¸ì‚¬ì´íŠ¸\n",
    "- CryoSleep=Trueì¸ ìŠ¹ê°ì˜ ì´ë™ë¥ ì´ ë†’ìŒ\n",
    "- ì–´ë¦°ì´(0-18ì„¸)ì˜ ì´ë™ë¥ ì´ ì„±ì¸ë³´ë‹¤ ë†’ìŒ\n",
    "- ì†Œë¹„ íŒ¨í„´ê³¼ ì´ë™ ì—¬ë¶€ì˜ ìƒê´€ê´€ê³„ ë°œê²¬\n",
    "- ê·¸ë£¹ í¬ê¸°ì— ë”°ë¥¸ ì´ë™ íŒ¨í„´ ì°¨ì´ ì¡´ì¬\n",
    "\n",
    "### ëª¨ë¸ë§ ê²°ê³¼\n",
    "- **ìµœì¢… ëª¨ë¸:** XGBoost (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)\n",
    "- **Validation ì •í™•ë„:** ì•½ 80%+\n",
    "- **ì£¼ìš” íŠ¹ì„±:** CryoSleep, Age, TotalSpending, Deck ë“±\n",
    "\n",
    "### ì œì¶œ\n",
    "- ì œì¶œ íŒŒì¼: `spaceship_titanic_submission.csv`\n",
    "- ì˜ˆì¸¡ ìŠ¹ê° ìˆ˜: 4,277ëª…\"\"\"))\n",
    "\n",
    "# ========== 9. íšŒê³  ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 9. íšŒê³  (Reflection)\n",
    "\n",
    "### ë°°ìš´ ì \n",
    "1. **EDAì˜ ì¤‘ìš”ì„±:** ë°ì´í„°ë¥¼ ê¹Šì´ ì´í•´í•˜ê³  íŒ¨í„´ì„ ë°œê²¬í•˜ëŠ” ê²ƒì´ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬\n",
    "2. **íŒŒìƒ ë³€ìˆ˜ ìƒì„±:** PassengerId, Cabin, Name ë“±ì—ì„œ ì¶”ê°€ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ\n",
    "3. **ë…¼ë¦¬ì  ê²°ì¸¡ì¹˜ ì²˜ë¦¬:** CryoSleep=True â†’ ì†Œë¹„ 0 ê°™ì€ ë…¼ë¦¬ì  ì¼ê´€ì„± ìœ ì§€\n",
    "\n",
    "### ì–´ë ¤ì› ë˜ ì \n",
    "1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ:** ì–´ë–¤ ë°©ë²•ì´ ìµœì„ ì¸ì§€ íŒë‹¨ì´ ì–´ë ¤ì› ìŒ\n",
    "2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹:** GridSearchCV ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼\n",
    "\n",
    "### ê°œì„  ë°©í–¥\n",
    "1. **ì•™ìƒë¸” ê¸°ë²•:** Voting, Stacking ë“±ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥\n",
    "2. **ì¶”ê°€ íŒŒìƒ ë³€ìˆ˜:** ë” ì°½ì˜ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "3. **ì´ìƒì¹˜ ì²˜ë¦¬:** ì†Œë¹„ ë³€ìˆ˜ì˜ ê·¹ë‹¨ê°’ ì²˜ë¦¬\n",
    "4. **êµì°¨ ê²€ì¦:** K-Fold CVë¡œ ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "### ì†Œê°\n",
    "ì²« Main Questë¥¼ í†µí•´ ë°ì´í„° ë¶„ì„ì˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. EDAë¶€í„° ëª¨ë¸ë§ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•˜ë©° ê° ê³¼ì •ì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ê³ , íŠ¹íˆ ë„ë©”ì¸ ì§€ì‹(ì˜ˆ: CryoSleepâ†’ì†Œë¹„ 0)ì„ í™œìš©í•œ ì „ì²˜ë¦¬ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ë°°ì› ìŠµë‹ˆë‹¤.\"\"\"))\n",
    "\n",
    "# ========== 10. References ==========\n",
    "cells.append(nbf.v4.new_markdown_cell(\"\"\"## 10. ì°¸ê³  ë¬¸í—Œ (References)\n",
    "\n",
    "1. **Kaggle Competition:** [Spaceship Titanic](https://www.kaggle.com/competitions/spaceship-titanic)\n",
    "2. **Baseline Code:** [ğŸš€ Spaceship Titanic: A complete guide ğŸ†](https://www.kaggle.com/code/example) (ê³¼ì œ ì°¸ì¡° ë§í¬)\n",
    "3. **Scikit-learn Documentation:** https://scikit-learn.org/\n",
    "4. **XGBoost Documentation:** https://xgboost.readthedocs.io/\n",
    "5. **Pandas Documentation:** https://pandas.pydata.org/\n",
    "6. **ì•„ì´í  ì—”ì§€ë‹ˆì–´ ì–‘ì„±ê³¼ì • êµìœ¡ ìë£Œ**\n",
    "\n",
    "---\n",
    "\n",
    "**í”„ë¡œì íŠ¸ ì™„ë£Œì¼:** 2026.01.26\n",
    "**ì‘ì„±ì:** Changil\"\"\"))\n",
    "\n",
    "# ë…¸íŠ¸ë¶ì— ì…€ ì¶”ê°€\n",
    "nb['cells'] = cells\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "notebook_filename = '/mnt/user-data/outputs/Space_Titanic_MainQuest01.ipynb'\n",
    "\n",
    "with open(notebook_filename, 'w', encoding='utf-8') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "print(f\"\\nâœ… Jupyter Notebook íŒŒì¼ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"íŒŒì¼ ìœ„ì¹˜: {notebook_filename}\")\n",
    "print(\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"1. ì´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ\")\n",
    "print(\"2. ë¡œì»¬ì—ì„œ Jupyter Notebookìœ¼ë¡œ ì—´ê¸°\")\n",
    "print(\"3. ê° ì…€ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰\")\n",
    "print(\"4. GitHubì— ì—…ë¡œë“œ (Main_Quest/Quest01/)\")\n",
    "print(\"5. 17ì‹œ 30ë¶„ê¹Œì§€ ì œì¶œ!\")"
   ],
   "id": "f8718888b02009a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Jupyter Notebook íŒŒì¼ ìƒì„± ì¤‘...\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/user-data/outputs/Space_Titanic_MainQuest01.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 657\u001B[39m\n\u001B[32m    654\u001B[39m \u001B[38;5;66;03m# íŒŒì¼ ì €ì¥\u001B[39;00m\n\u001B[32m    655\u001B[39m notebook_filename = \u001B[33m'\u001B[39m\u001B[33m/mnt/user-data/outputs/Space_Titanic_MainQuest01.ipynb\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m657\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnotebook_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mw\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    658\u001B[39m     nbf.write(nb, f)\n\u001B[32m    660\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mâœ… Jupyter Notebook íŒŒì¼ ìƒì„± ì™„ë£Œ!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:344\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    338\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    339\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    341\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    342\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '/mnt/user-data/outputs/Space_Titanic_MainQuest01.ipynb'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
